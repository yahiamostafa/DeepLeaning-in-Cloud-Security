{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yahiamostafa/DeepLeaning-in-Cloud-Security/blob/main/DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lN_et7fqcEtU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.utils import class_weight\n",
        "import tensorflow.keras.layers as tkl\n",
        "\n",
        "seed = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dl2qtSsMILy",
        "outputId": "0df44c84-874a-44f6-9fa1-55e493c4a060"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Y0wRe3vcPf7"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "fill data method to add the missed columns to test data \n",
        "to make the number of features in the train and the test equal.\n",
        "'''\n",
        "def fillData(trainInput , testInput):\n",
        "    trainCols = trainInput.columns\n",
        "    testCols = testInput.columns\n",
        "    mask = np.in1d(trainCols , testCols)\n",
        "    neededCols = np.where(~mask)[0]\n",
        "    for col in neededCols[::-1]:\n",
        "        testInput.insert(loc = int(col) , column = trainCols[col] , value = 0)\n",
        "    return testInput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTVdA96OcW9r"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Normal Logistic Regression algorithm \n",
        "changing the number of iterations to improve the effciency.\n",
        "'''\n",
        "def logisticRegression(trainInput , trainOutput , testInput , testOutput):\n",
        "    model = LogisticRegression(max_iter=300)\n",
        "    model.fit(trainInput , trainOutput)\n",
        "    print(model.score(trainInput , trainOutput))\n",
        "    print(model.score(testInput , testOutput))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDtzViaUcY0b"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Data Prepocessing including\n",
        "1- reading the csv file.\n",
        "2- seperate the output from the file.\n",
        "3- Applying OneHotEnocder to encode categorical features  into neumrical.\n",
        "4- Normalizing data to make the gredient descent run faster. \n",
        "'''\n",
        "def preprocessingBinaryClass(filePath , scaler = MinMaxScaler() , hotencoder = OneHotEncoder(), train = True , isCnn = False):\n",
        "    dataframe = pd.read_csv(filePath , header = None)\n",
        "\n",
        "     # to move the first Row to the last Position\n",
        "    # firstRow = dataframe.iloc[0]\n",
        "    # dataframe.drop(labels= 0 , axis= 0 , inplace= True)\n",
        "    # dataframe = dataframe.append(firstRow , ignore_index = True)\n",
        "    dataframe.columns = getFeaturesNames()\n",
        "    dataframe.drop(['level'] , axis= 1 , inplace=True)\n",
        "    output=dataframe['classification'].values\n",
        "    output = output == 'normal'\n",
        "    dataframe.drop(['classification']  , axis= 1,inplace=True)\n",
        "    catFeatures =  dataframe.select_dtypes(include = \"object\")\n",
        "    dataframe.drop(catFeatures.columns , axis= 1 , inplace= True)\n",
        "    if train :\n",
        "        scaler.fit(dataframe)\n",
        "        hotencoder.fit(catFeatures)\n",
        "    encodedDataframe = pd.DataFrame(hotencoder.transform(catFeatures).toarray())\n",
        "    encodedDataframe.columns = hotencoder.get_feature_names_out()\n",
        "    tempCols = dataframe.columns\n",
        "    dataframe = pd.DataFrame(scaler.transform(dataframe) , columns = tempCols)\n",
        "    dataframe = pd.concat([dataframe , encodedDataframe] , axis= 1)\n",
        "    if isCnn:\n",
        "      dataframe.drop(['num_outbound_cmds'] , axis= 1 , inplace=True)\n",
        "      dataframe = dataframe.values.reshape(dataframe.shape[0] , 11 , 11 , 1)\n",
        "    return dataframe , output , scaler ,hotencoder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bTt3TKZca25"
      },
      "outputs": [],
      "source": [
        "def outputMapping(arr):\n",
        "    \n",
        "    multiclass_attack={ 'normal': 'normal', \n",
        "        'probe': ['ipsweep.', 'nmap.', 'portsweep.','satan.', 'saint.', 'mscan.'], \n",
        "        'dos': ['back.', 'land.', 'neptune.', 'pod.', 'smurf.','teardrop.', 'apache2.', 'udpstorm.', 'processtable.','mailbomb.'], \n",
        "        'u2r': ['buffer_overflow.', 'loadmodule.', 'perl.', 'rootkit.','xterm.', 'ps.', 'sqlattack.'], \n",
        "        'r2l': ['ftp_write.', 'guess_passwd.', 'imap.', 'multihop.','phf.', 'spy.', 'warezclient.', 'warezmaster.','snmpgetattack.', \n",
        "                   'named.', 'xlock.', 'xsnoop.','sendmail.', 'httptunnel.', 'worm.', 'snmpguess.']}\n",
        "\n",
        "    attacks = ['normal' , 'probe' , 'dos' , 'u2r' ,'r2l']\n",
        "    \n",
        "    for element in np.unique(arr):\n",
        "        for attack in attacks:\n",
        "            if element +\".\" in multiclass_attack[attack]:\n",
        "                arr[ arr == element] = attack\n",
        "    \n",
        "    return arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kddPpmsxcd9u"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Data Prepocessing including\n",
        "1- reading the csv file.\n",
        "2- seperate the output from the file.\n",
        "3- Applying OneHotEnocder to encode categorical features  into neumrical.\n",
        "4- Normalizing data to make the gredient descent run faster. \n",
        "'''\n",
        "def preprocessingFiveClasses(filePath , scaler = MinMaxScaler() , inEncoder = OneHotEncoder() , outEncoder = OneHotEncoder() , train = True , isCnn = False):\n",
        "  dataframe = pd.read_csv(filePath , header = None)\n",
        "  dataframe.columns = getFeaturesNames()\n",
        "  dataframe.drop(['level'] , axis= 1 , inplace=True)\n",
        "  output=outputMapping(pd.DataFrame(dataframe['classification']).values)\n",
        "  dataframe.drop(['classification']  , axis= 1,inplace=True)\n",
        "  catFeatures =  dataframe.select_dtypes(include = \"object\")\n",
        "  dataframe.drop(catFeatures.columns , axis= 1 , inplace= True)\n",
        "  out = output\n",
        "  if train :\n",
        "      scaler.fit(dataframe)\n",
        "      inEncoder.fit(catFeatures)\n",
        "      outEncoder.fit(output)\n",
        "  output = pd.DataFrame(outEncoder.transform(output).toarray())\n",
        "  encodedDataframe = pd.DataFrame(inEncoder.transform(catFeatures).toarray())\n",
        "  encodedDataframe.columns = inEncoder.get_feature_names_out()\n",
        "  tempCols = dataframe.columns\n",
        "  dataframe = pd.DataFrame(scaler.transform(dataframe) , columns = tempCols)\n",
        "  dataframe = pd.concat([dataframe , encodedDataframe] , axis= 1)\n",
        "  if isCnn :\n",
        "    dataframe.drop(['num_outbound_cmds'] , axis= 1 , inplace=True)\n",
        "    dataframe = dataframe.values.reshape(dataframe.shape[0] , 11 , 11 , 1)\n",
        "  return dataframe , output , out ,  scaler ,inEncoder , outEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHzn1IGnckHe"
      },
      "outputs": [],
      "source": [
        "def getFeaturesNames():\n",
        "    features_name = pd.read_csv('drive/MyDrive/Field Names.csv')\n",
        "    cols_name = features_name['duration'].tolist()\n",
        "    cols_name.insert(0 , \"duration\")\n",
        "    cols_name.append('classification')\n",
        "    cols_name.append('level')\n",
        "    return cols_name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WHpWZ-gcl5R"
      },
      "outputs": [],
      "source": [
        "def MPLClassification(trainInput , trainOutput , testInput , testOutput):\n",
        "    model = MLPClassifier(solver = 'adam' , alpha=0.0001 , max_iter= 200 , hidden_layer_sizes=(352 , 64 , 480 , 320 ,128) , random_state= 10 , batch_size=122)\n",
        "    model.fit(trainInput , trainOutput)\n",
        "    print(model.score(trainInput , trainOutput))\n",
        "    print(model.score(testInput , testOutput))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pahapKZ7coHh"
      },
      "outputs": [],
      "source": [
        "def predictTFresults(model , X , Y):\n",
        "    pred = model.evaluate( X , Y , batch_size = 128)\n",
        "    return {\"Cost Function\" : pred[0] , 'Accuracy' : pred[1]* 100}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArxxxejZcp78"
      },
      "outputs": [],
      "source": [
        "    def initTFparams(trainInput , trainOutput , lr , stddev , epochs ):\n",
        "\n",
        "        print(f\"lr {lr} and stddev {stddev}\")\n",
        "        np.random.seed(100)\n",
        "        tf.random.set_seed(100)\n",
        "        input_batch_size=122\n",
        "        inputs = keras.Input(shape=(input_batch_size,), name=\"inputs\")\n",
        "        layer=layers.Dense(128, activation=\"relu\", name=\"hidden_layer_1\" , kernel_initializer=initializers.RandomNormal(stddev=stddev), bias_initializer=initializers.Zeros())(inputs)\n",
        "        layer=layers.Dense(256, activation=\"relu\", name=\"hidden_layer_2\" , kernel_initializer=initializers.RandomNormal(stddev=stddev), bias_initializer=initializers.Zeros())(layer)\n",
        "        layer=layers.Dense(512, activation=\"relu\", name=\"hidden_layer_3\" , kernel_initializer=initializers.RandomNormal(stddev=stddev), bias_initializer=initializers.Zeros())(layer)\n",
        "        layer=layers.Dense(1024, activation=\"relu\", name=\"hidden_layer_4\" , kernel_initializer=initializers.RandomNormal(stddev=stddev), bias_initializer=initializers.Zeros())(layer)\n",
        "        layer=layers.Dense(256, activation=\"relu\", name=\"hidden_layer_5\" , kernel_initializer=initializers.RandomNormal(stddev=stddev), bias_initializer=initializers.Zeros())(layer)\n",
        "        layer=layers.Dense(64, activation=\"relu\", name=\"hidden_layer_6\" , kernel_initializer=initializers.RandomNormal(stddev=stddev), bias_initializer=initializers.Zeros())(layer)\n",
        "        outputs=layers.Dense(1,activation=\"sigmoid\" ,name=\"output\" , kernel_initializer=initializers.RandomNormal(stddev=stddev), bias_initializer=initializers.Zeros())(layer)\n",
        "        model=keras.Model(inputs=inputs,outputs=outputs)\n",
        "        model._name=\"MPLBinaryClassification\"\n",
        "        model.compile(loss='binary_crossentropy',optimizer=tf.optimizers.Adam(learning_rate=lr),metrics=['accuracy'])\n",
        "        model.fit(trainInput, trainOutput,epochs=epochs,batch_size=128 , validation_data=[testInput , testOutput])\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "PJA0Ovx3w19n",
        "outputId": "023d918c-c4ba-4993-9a23-69e370ff12a9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1ba6ae8e0bfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstddev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0minitTFparams2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainInput\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtrainOutput\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'initTFparams2' is not defined"
          ]
        }
      ],
      "source": [
        "for i in range(0, 3):\n",
        "  for j in range(7):\n",
        "    lr = 10 ** (-1 * i)\n",
        "    stddev = 10 ** (-1 * j)\n",
        "    initTFparams2(trainInput , trainOutput , lr , stddev , 100 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5p2JfOLwjV7"
      },
      "outputs": [],
      "source": [
        "    def initTFparams2(trainInput , trainOutput , lr , stddev , epochs ):\n",
        "\n",
        "        print(f\"lr {lr} and stddev {stddev}\")\n",
        "        np.random.seed(100)\n",
        "        tf.random.set_seed(100)\n",
        "        input_batch_size=122\n",
        "        inputs = keras.Input(shape=(input_batch_size,), name=\"inputs\")\n",
        "        layer=layers.Dense(102, activation=\"relu\", name=\"hidden_layer_1\" , kernel_initializer=initializers.RandomNormal(stddev=stddev), bias_initializer=initializers.Zeros())(inputs)\n",
        "        layer=layers.Dense(50, activation=\"relu\", name=\"hidden_layer_2\" , kernel_initializer=initializers.RandomNormal(stddev=stddev), bias_initializer=initializers.Zeros())(layer)\n",
        "        # layer=layers.Dense(512, activation=\"relu\", name=\"hidden_layer_3\" , kernel_initializer=initializers.RandomNormal(stddev=stddev), bias_initializer=initializers.Zeros())(layer)\n",
        "        # # layer=layers.Dense(1024, activation=\"relu\", name=\"hidden_layer_4\" , kernel_initializer=initializers.RandomNormal(stddev=stddev), bias_initializer=initializers.Zeros())(layer)\n",
        "        # # layer=layers.Dense(256, activation=\"relu\", name=\"hidden_layer_5\" , kernel_initializer=initializers.RandomNormal(stddev=stddev), bias_initializer=initializers.Zeros())(layer)\n",
        "        # # layer=layers.Dense(64, activation=\"relu\", name=\"hidden_layer_6\" , kernel_initializer=initializers.RandomNormal(stddev=stddev), bias_initializer=initializers.Zeros())(layer)\n",
        "        outputs=layers.Dense(1,activation=\"sigmoid\" ,name=\"output\" , kernel_initializer=initializers.RandomNormal(stddev=stddev), bias_initializer=initializers.Zeros())(layer)\n",
        "        model=keras.Model(inputs=inputs,outputs=outputs)\n",
        "        model._name=\"MPLBinaryClassification\"\n",
        "        model.compile(loss='binary_crossentropy',optimizer=tf.optimizers.Adam(learning_rate=lr),metrics=['accuracy'])\n",
        "        model.fit(trainInput, trainOutput,epochs=epochs,batch_size=128 , validation_data=[testInput , testOutput])\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxkuvobRxYnT",
        "outputId": "1c838f82-72c3-4d53-8319-8933a052eb28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lr 0.1 and stddev 1\n",
            "Epoch 1/18\n",
            "985/985 [==============================] - 4s 3ms/step - loss: 0.3016 - accuracy: 0.9809 - val_loss: 1.7804 - val_accuracy: 0.7738\n",
            "Epoch 2/18\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.0280 - accuracy: 0.9896 - val_loss: 2.0417 - val_accuracy: 0.7781\n",
            "Epoch 3/18\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.0237 - accuracy: 0.9907 - val_loss: 1.9974 - val_accuracy: 0.7834\n",
            "Epoch 4/18\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.0361 - accuracy: 0.9882 - val_loss: 2.3866 - val_accuracy: 0.7808\n",
            "Epoch 5/18\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.0323 - accuracy: 0.9896 - val_loss: 4.9364 - val_accuracy: 0.8075\n",
            "Epoch 6/18\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.0322 - accuracy: 0.9901 - val_loss: 4.2661 - val_accuracy: 0.7933\n",
            "Epoch 7/18\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.0482 - accuracy: 0.9875 - val_loss: 4.9087 - val_accuracy: 0.8224\n",
            "Epoch 8/18\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.0368 - accuracy: 0.9894 - val_loss: 22.4069 - val_accuracy: 0.8269\n",
            "Epoch 9/18\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.2092 - accuracy: 0.9249 - val_loss: 10.8242 - val_accuracy: 0.6575\n",
            "Epoch 10/18\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.1384 - accuracy: 0.9435 - val_loss: 3.9362 - val_accuracy: 0.7985\n",
            "Epoch 11/18\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.0361 - accuracy: 0.9892 - val_loss: 9.3652 - val_accuracy: 0.7802\n",
            "Epoch 12/18\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.0351 - accuracy: 0.9895 - val_loss: 8.1010 - val_accuracy: 0.7919\n",
            "Epoch 13/18\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.0376 - accuracy: 0.9900 - val_loss: 6.4526 - val_accuracy: 0.8225\n",
            "Epoch 14/18\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.0309 - accuracy: 0.9914 - val_loss: 3.5665 - val_accuracy: 0.7960\n",
            "Epoch 15/18\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.0307 - accuracy: 0.9914 - val_loss: 20.3801 - val_accuracy: 0.8049\n",
            "Epoch 16/18\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.0292 - accuracy: 0.9921 - val_loss: 24.9827 - val_accuracy: 0.7810\n",
            "Epoch 17/18\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.0305 - accuracy: 0.9918 - val_loss: 19.1219 - val_accuracy: 0.7892\n",
            "Epoch 18/18\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.1826 - accuracy: 0.9419 - val_loss: 26.2422 - val_accuracy: 0.8960\n",
            "985/985 [==============================] - 2s 2ms/step - loss: 0.1146 - accuracy: 0.9418\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 26.2422 - accuracy: 0.8960\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 49.9059 - accuracy: 0.8196\n"
          ]
        }
      ],
      "source": [
        "lr = 0.1\n",
        "stddev = 1\n",
        "epochs = 18\n",
        "model = initTFparams2(trainInput , trainOutput , lr , stddev , epochs ) \n",
        "with open('drive/MyDrive/resultForMLPBinay.txt' , 'a') as file:\n",
        "    file.write('___________________________________________________________________________________________________\\n')\n",
        "    file.write(f' lr = {lr} , stddev = {stddev} , epochs = {epochs}  , seed = {seed}  MLP2\\n')\n",
        "    file.write(str(predictTFresults(model , trainInput , trainOutput))+ '\\n')\n",
        "    file.write(str(predictTFresults(model , testInput , testOutput))+'\\n')\n",
        "    file.write(str(predictTFresults(model , test21Input , test21Output))+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzmbY98EcufV"
      },
      "outputs": [],
      "source": [
        "def initTFparamsDiffClasses(trainInput , trainOutput ):   \n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    input_batch_size=trainInput.shape[1]\n",
        "    inputs = keras.Input(shape=(input_batch_size,), name=\"inputs\")\n",
        "    layer=layers.Dense(128, activation=\"relu\", name=\"hidden_layer_1\" , kernel_initializer=initializers.RandomNormal(stddev=0.01), bias_initializer=initializers.Zeros())(inputs)\n",
        "    layer=layers.Dense(256, activation=\"relu\", name=\"hidden_layer_2\" , kernel_initializer=initializers.RandomNormal(stddev=0.01), bias_initializer=initializers.Zeros())(layer)\n",
        "    layer=layers.Dense(512, activation=\"relu\", name=\"hidden_layer_3\" , kernel_initializer=initializers.RandomNormal(stddev=0.01), bias_initializer=initializers.Zeros())(layer)\n",
        "    layer=layers.Dense(1024, activation=\"relu\", name=\"hidden_layer_4\" , kernel_initializer=initializers.RandomNormal(stddev=0.01), bias_initializer=initializers.Zeros())(layer)\n",
        "    layer=layers.Dense(256, activation=\"relu\", name=\"hidden_layer_5\" , kernel_initializer=initializers.RandomNormal(stddev=0.01), bias_initializer=initializers.Zeros())(layer)\n",
        "    layer=layers.Dense(64, activation=\"relu\", name=\"hidden_layer_6\" , kernel_initializer=initializers.RandomNormal(stddev=0.01), bias_initializer=initializers.Zeros())(layer)\n",
        "    outputs=layers.Dense(5,activation=\"softmax\" ,name=\"output\" , kernel_initializer=initializers.RandomNormal(stddev=0.01), bias_initializer=initializers.Zeros())(layer)\n",
        "    model=keras.Model(inputs=inputs,outputs=outputs)\n",
        "    model._name=\"MPLDifferentClassification\"\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=tf.optimizers.Adam(learning_rate=0.001),metrics=['accuracy'])\n",
        "    model.fit(trainInput, trainOutput, epochs=100, batch_size=128 , validation_data=[testInput , testOutput])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l7zkymtR3fb"
      },
      "outputs": [],
      "source": [
        "def initTFparamsDiffClasses2(trainInput , trainOutput , lr , stddev , epochs  ):   \n",
        "    print(f\"lr {lr} and stddev {stddev}\")\n",
        "    np.random.seed(100)\n",
        "    tf.random.set_seed(100)\n",
        "    input_batch_size=trainInput.shape[1]\n",
        "    inputs = keras.Input(shape=(input_batch_size,), name=\"inputs\")\n",
        "    layer=layers.Dense(102, activation=\"relu\", name=\"hidden_layer_1\" , kernel_initializer=initializers.RandomNormal(stddev=stddev), bias_initializer=initializers.Zeros())(inputs)\n",
        "    layer=layers.Dense(50, activation=\"relu\", name=\"hidden_layer_2\" , kernel_initializer=initializers.RandomNormal(stddev=stddev), bias_initializer=initializers.Zeros())(layer)\n",
        "    outputs=layers.Dense(5,activation=\"softmax\" ,name=\"output\" , kernel_initializer=initializers.RandomNormal(stddev=stddev), bias_initializer=initializers.Zeros())(layer)\n",
        "    model=keras.Model(inputs=inputs,outputs=outputs)\n",
        "    model._name=\"MPLDifferentClassification\"\n",
        "\n",
        "    class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(out),\n",
        "    y=out.reshape(-1)\n",
        "    )\n",
        "  \n",
        "    class_weights = dict(zip([0,1,2,3,4],class_weights))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=tf.optimizers.Adam(learning_rate= lr),metrics=['accuracy'])\n",
        "    model.fit(trainInput, trainOutput, epochs=epochs, batch_size=128 , validation_data=[testInput , testOutput] , class_weight = class_weights)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1kZ__eEvCoji",
        "outputId": "df6fad6a-24b8-47fb-c743-c3ea0f723db3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lr 0.1 and stddev 1\n",
            "Epoch 1/44\n",
            "985/985 [==============================] - 4s 4ms/step - loss: 29.0623 - accuracy: 0.8708 - val_loss: 12.8987 - val_accuracy: 0.7445\n",
            "Epoch 2/44\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.5160 - accuracy: 0.8863 - val_loss: 11.4964 - val_accuracy: 0.7909\n",
            "Epoch 3/44\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.4552 - accuracy: 0.8992 - val_loss: 10.5889 - val_accuracy: 0.7751\n",
            "Epoch 4/44\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.6257 - accuracy: 0.8868 - val_loss: 7.8169 - val_accuracy: 0.6717\n",
            "Epoch 5/44\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.6071 - accuracy: 0.8683 - val_loss: 14.6944 - val_accuracy: 0.7549\n",
            "Epoch 6/44\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.6174 - accuracy: 0.8697 - val_loss: 10.3504 - val_accuracy: 0.7328\n",
            "Epoch 7/44\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.6725 - accuracy: 0.8325 - val_loss: 15.4134 - val_accuracy: 0.6284\n",
            "Epoch 8/44\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.8229 - accuracy: 0.7795 - val_loss: 24.2355 - val_accuracy: 0.4215\n",
            "Epoch 9/44\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 1.2865 - accuracy: 0.3010 - val_loss: 10.4829 - val_accuracy: 0.1853\n",
            "Epoch 10/44\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 1.3073 - accuracy: 0.2783 - val_loss: 9.9939 - val_accuracy: 0.4958\n",
            "Epoch 11/44\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 0.9532 - accuracy: 0.6346 - val_loss: 17.3773 - val_accuracy: 0.3675\n",
            "Epoch 12/44\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 1.0227 - accuracy: 0.6473 - val_loss: 24.9932 - val_accuracy: 0.2789\n",
            "Epoch 13/44\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 1.2212 - accuracy: 0.4504 - val_loss: 17.8610 - val_accuracy: 0.0664\n",
            "Epoch 14/44\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 1.3136 - accuracy: 0.2472 - val_loss: 9.3994 - val_accuracy: 0.1878\n",
            "Epoch 15/44\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 1.2955 - accuracy: 0.2542 - val_loss: 10.7399 - val_accuracy: 0.3779\n",
            "Epoch 16/44\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 1.2895 - accuracy: 0.2726 - val_loss: 4.7619 - val_accuracy: 0.0530\n",
            "Epoch 17/44\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 1.3449 - accuracy: 0.3013 - val_loss: 15.9073 - val_accuracy: 0.3459\n",
            "Epoch 18/44\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 1.4058 - accuracy: 0.2158 - val_loss: 21.1180 - val_accuracy: 0.1789\n",
            "Epoch 19/44\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 1.3531 - accuracy: 0.2319 - val_loss: 16.3257 - val_accuracy: 0.0287\n",
            "Epoch 20/44\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 1.3633 - accuracy: 0.2338 - val_loss: 33.0393 - val_accuracy: 0.1015\n",
            "Epoch 21/44\n",
            "985/985 [==============================] - 3s 3ms/step - loss: 2.1890 - accuracy: 0.2057 - val_loss: 54.3809 - val_accuracy: 0.3858\n",
            "Epoch 22/44\n",
            "420/985 [===========>..................] - ETA: 1s - loss: 1.3743 - accuracy: 0.2136"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-838bc4c4203c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m44\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitTFparamsDiffClasses2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainInput\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtrainOutput\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/MyDrive/resultForMLPMultiClassification.txt'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'___________________________________________________________________________________________________\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-e3b8b695ba09>\u001b[0m in \u001b[0;36minitTFparamsDiffClasses2\u001b[0;34m(trainInput, trainOutput, lr, stddev, epochs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestInput\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtestOutput\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "lr = 0.1\n",
        "stddev = 1\n",
        "epochs = 44\n",
        "seed = 100\n",
        "model = initTFparamsDiffClasses2(trainInput , trainOutput , lr , stddev , epochs) \n",
        "with open('drive/MyDrive/resultForMLPMultiClassification.txt' , 'a') as file:\n",
        "    file.write('___________________________________________________________________________________________________\\n')\n",
        "    file.write(f' lr = {lr} , stddev = {stddev} , epochs = {epochs}  , seed = {seed} MLP2 \\n')\n",
        "    file.write(str(predictTFresults(model , trainInput , trainOutput))+ '\\n')\n",
        "    file.write(str(predictTFresults(model , testInput , testOutput))+'\\n')\n",
        "    file.write(str(predictTFresults(model , test21Input , test21Output))+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wN05tLonOAyU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "c73b2b94-07b2-44e0-c12f-eb74f270d516"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-a2ed1391b585>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    layer = tkl.Conv2D(filters = 20 , input_shape = (5,5,20) , kernel_size=(2,2) , name ='conv2D1' )(inputs)u7y\u001b[0m\n\u001b[0m                                                                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "def conv2DBinary( X , Y , lr , stddev , epochs ,seed):\n",
        "\n",
        "  print (lr , stddev , seed ,  sep =' ')\n",
        "  np.random.seed(seed)\n",
        "  tf.random.set_seed(seed)\n",
        "\n",
        "  inputs = tkl.Input(shape=(11,11,1), name=\"inputs\")\n",
        "\n",
        "  layer = tkl.Conv2D(filters = 20 , input_shape = (5,5,20) , kernel_size=(2,2) , name ='conv2D1' )(inputs)\n",
        "  layer = tkl.MaxPool2D(name = 'maxpool2D1')(layer)\n",
        "  layer = tkl.BatchNormalization( name ='batchNorm1')(layer)\n",
        "  layer = tkl.Activation(\"relu\")(layer)\n",
        "\n",
        "  layer = tkl.Conv2D(filters = 40 , input_shape = (2,2,40) , kernel_size=(2,2) , name ='conv2D2' )(layer)\n",
        "  layer = tkl.MaxPool2D(name = 'maxpool2D2')(layer)\n",
        "  layer = tkl.BatchNormalization( name ='batchNorm2')(layer)\n",
        "  layer = tkl.Activation(\"relu\")(layer)\n",
        "\n",
        "  layer = tkl.Conv2D(filters = 60 , input_shape = (1,1,60) , kernel_size=(2,2) , name ='conv2D3' )(layer)\n",
        "  layer = tkl.BatchNormalization( name ='batchNorm3')(layer)\n",
        "  layer = tkl.Activation(\"relu\")(layer)\n",
        "\n",
        "  layer = tkl.Flatten()(layer)\n",
        "\n",
        "  layer = tkl.Dense(64, name = 'FC1' ,kernel_initializer=initializers.RandomNormal(stddev= stddev))(layer)\n",
        "  layer = tkl.BatchNormalization( name ='batchNorm4')(layer)\n",
        "  layer = tkl.Activation(\"relu\")(layer)\n",
        "\n",
        "  layer = tkl.Dense(80, name = 'FC2' , kernel_initializer=initializers.RandomNormal(stddev= stddev))(layer)\n",
        "  layer = tkl.BatchNormalization( name ='batchNorm5')(layer)\n",
        "  layer = tkl.Activation(\"relu\")(layer)\n",
        "\n",
        "  layer = tkl.Dense(25, name = 'FC3' ,  kernel_initializer=initializers.RandomNormal(stddev= stddev))(layer)\n",
        "  layer = tkl.BatchNormalization( name ='batchNorm6')(layer)\n",
        "  layer = tkl.Activation(\"relu\")(layer)\n",
        "\n",
        "  outputs = tkl.Dense(1 ,name=\"output\" , activation = 'sigmoid' , kernel_initializer=initializers.RandomNormal(stddev= stddev))(layer)\n",
        "  \n",
        "  model=keras.Model(inputs=inputs,outputs=outputs)\n",
        "\n",
        "\n",
        "  model.compile(loss='binary_crossentropy' , optimizer=tf.optimizers.Adam(learning_rate= lr) , metrics=['accuracy'] )\n",
        "  model.fit( X , Y , epochs= epochs , batch_size=128 , validation_data = [test21Input,test21Output] )\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = conv2DMultiClass(trainInput , trainOutput , 0.0001 , 1 , 13)\n",
        "\n",
        "print(predictTFresults(model , trainInput , trainOutput))\n",
        "print(predictTFresults(model , testInput , testOutput))\n",
        "print(predictTFresults(model , test21Input , test21Output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZAyXhYydG_R",
        "outputId": "865372b1-28f9-467c-d20f-e3a12424ea2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0001 1\n",
            "Epoch 1/13\n",
            "985/985 [==============================] - 17s 15ms/step - loss: 1.6038 - accuracy: 0.7098 - val_loss: 2.6749 - val_accuracy: 0.4163\n",
            "Epoch 2/13\n",
            "985/985 [==============================] - 13s 13ms/step - loss: 0.5980 - accuracy: 0.8477 - val_loss: 2.1587 - val_accuracy: 0.4980\n",
            "Epoch 3/13\n",
            "985/985 [==============================] - 13s 13ms/step - loss: 0.4050 - accuracy: 0.8965 - val_loss: 2.0662 - val_accuracy: 0.5378\n",
            "Epoch 4/13\n",
            "985/985 [==============================] - 13s 13ms/step - loss: 0.3176 - accuracy: 0.9178 - val_loss: 1.9658 - val_accuracy: 0.5436\n",
            "Epoch 5/13\n",
            "985/985 [==============================] - 12s 13ms/step - loss: 0.2735 - accuracy: 0.9256 - val_loss: 1.7601 - val_accuracy: 0.5608\n",
            "Epoch 6/13\n",
            "985/985 [==============================] - 12s 13ms/step - loss: 0.2472 - accuracy: 0.9339 - val_loss: 1.5665 - val_accuracy: 0.5968\n",
            "Epoch 7/13\n",
            "985/985 [==============================] - 13s 13ms/step - loss: 0.1936 - accuracy: 0.9404 - val_loss: 1.5661 - val_accuracy: 0.6181\n",
            "Epoch 8/13\n",
            "985/985 [==============================] - 12s 13ms/step - loss: 0.2012 - accuracy: 0.9469 - val_loss: 1.5551 - val_accuracy: 0.6351\n",
            "Epoch 9/13\n",
            "985/985 [==============================] - 13s 13ms/step - loss: 0.1696 - accuracy: 0.9536 - val_loss: 1.5677 - val_accuracy: 0.6273\n",
            "Epoch 10/13\n",
            "985/985 [==============================] - 13s 13ms/step - loss: 0.1554 - accuracy: 0.9576 - val_loss: 1.5310 - val_accuracy: 0.6547\n",
            "Epoch 11/13\n",
            "985/985 [==============================] - 13s 13ms/step - loss: 0.1570 - accuracy: 0.9587 - val_loss: 1.6812 - val_accuracy: 0.6355\n",
            "Epoch 12/13\n",
            "985/985 [==============================] - 13s 13ms/step - loss: 0.1328 - accuracy: 0.9609 - val_loss: 1.7041 - val_accuracy: 0.6132\n",
            "Epoch 13/13\n",
            "985/985 [==============================] - 13s 13ms/step - loss: 0.1357 - accuracy: 0.9623 - val_loss: 1.5045 - val_accuracy: 0.6670\n",
            "985/985 [==============================] - 5s 5ms/step - loss: 0.1156 - accuracy: 0.9612\n",
            "{'Cost Function': 0.11563698202371597, 'Accuracy': 96.12138867378235}\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.8163 - accuracy: 0.8182\n",
            "{'Cost Function': 0.8163332343101501, 'Accuracy': 81.81697130203247}\n",
            "93/93 [==============================] - 0s 5ms/step - loss: 1.5045 - accuracy: 0.6670\n",
            "{'Cost Function': 1.5045019388198853, 'Accuracy': 66.70042276382446}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lsAldhj1g4O"
      },
      "outputs": [],
      "source": [
        "def conv2DMultiClass( X , Y , lr , stddev , epochs) :\n",
        "\n",
        "  print (lr , stddev ,  sep =' ')\n",
        "  np.random.seed(100)\n",
        "  tf.random.set_seed(100)\n",
        "\n",
        "  inputs = tkl.Input(shape=(11,11,1), name=\"inputs\")\n",
        "\n",
        "  layer = tkl.Conv2D(filters = 20 , input_shape = (5,5,20) , kernel_size=(2,2) , name ='conv2D1' )(inputs)\n",
        "  layer = tkl.MaxPool2D(name = 'maxpool2D1')(layer)\n",
        "  layer = tkl.BatchNormalization( name ='batchNorm1')(layer)\n",
        "  layer = tkl.Activation(\"relu\")(layer)\n",
        "\n",
        "  layer = tkl.Conv2D(filters = 40 , input_shape = (2,2,40) , kernel_size=(2,2) , name ='conv2D2' )(layer)\n",
        "  layer = tkl.MaxPool2D(name = 'maxpool2D2')(layer)\n",
        "  layer = tkl.BatchNormalization( name ='batchNorm2')(layer)\n",
        "  layer = tkl.Activation(\"relu\")(layer)\n",
        "\n",
        "  layer = tkl.Conv2D(filters = 60 , input_shape = (1,1,60) , kernel_size=(2,2) , name ='conv2D3' )(layer)\n",
        "  layer = tkl.BatchNormalization( name ='batchNorm3')(layer)\n",
        "  layer = tkl.Activation(\"relu\")(layer)\n",
        "\n",
        "  layer = tkl.Flatten()(layer)\n",
        "\n",
        "  layer = tkl.Dense(64, name = 'FC1' ,kernel_initializer=initializers.RandomNormal(stddev= stddev))(layer)\n",
        "  layer = tkl.BatchNormalization( name ='batchNorm4')(layer)\n",
        "  layer = tkl.Activation(\"relu\")(layer)\n",
        "\n",
        "  layer = tkl.Dense(80, name = 'FC2' , kernel_initializer=initializers.RandomNormal(stddev= stddev))(layer)\n",
        "  layer = tkl.BatchNormalization( name ='batchNorm5')(layer)\n",
        "  layer = tkl.Activation(\"relu\")(layer)\n",
        "\n",
        "  layer = tkl.Dense(25, name = 'FC3' ,  kernel_initializer=initializers.RandomNormal(stddev= stddev))(layer)\n",
        "  layer = tkl.BatchNormalization( name ='batchNorm6')(layer)\n",
        "  layer = tkl.Activation(\"relu\")(layer)\n",
        "\n",
        "  outputs = tkl.Dense(5 ,name=\"output\" , activation = 'softmax' , kernel_initializer=initializers.RandomNormal(stddev= stddev))(layer)\n",
        "  \n",
        "  model=keras.Model(inputs=inputs,outputs=outputs)\n",
        "\n",
        "\n",
        "  class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(out),\n",
        "    y=out.reshape(-1)\n",
        "  )\n",
        "  \n",
        "  class_weights = dict(zip([0,1,2,3,4],class_weights))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy' , optimizer=tf.optimizers.Adam(learning_rate= lr) , metrics=['accuracy'] )\n",
        "  model.fit( X , Y , epochs= epochs , batch_size=128 , validation_data = [test21Input,test21Output] , class_weight = class_weights )\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLXu1i0_OO4n"
      },
      "outputs": [],
      "source": [
        "def CNN_BLSTM(input_train,output_train , lr , stddev):\n",
        "\n",
        "\n",
        "    print(f\"lr {lr} and stddev{ stddev}\")\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    model = Sequential()\n",
        "    init = initializers.RandomNormal(stddev= stddev)\n",
        "    model.add(layers.Reshape((1,122), input_shape=(None,122)))\n",
        "    model.add(keras.layers.Conv1D(filters=40,activation=\"tanh\",name=\"Conv1d1\",kernel_size=2,strides=1,padding=\"same\",use_bias=True,bias_initializer=initializers.Zeros(),kernel_initializer=init))\n",
        "    model.add(keras.layers.MaxPool1D(pool_size=2,strides=1,name=\"MaxPooling1\",padding=\"same\"))\n",
        "    model.add(keras.layers.SpatialDropout1D(rate=0.1,name=\"Dropout_layer1\"))\n",
        "    model.add(keras.layers.Conv1D(filters=60,activation=\"tanh\",name=\"Conv1d2\",kernel_size=3,strides=1,padding=\"same\",use_bias=True,bias_initializer=initializers.Zeros(),kernel_initializer=init))\n",
        "    model.add(keras.layers.MaxPool1D(pool_size=3,strides=1,name=\"MaxPooling2\",padding=\"same\"))\n",
        "    model.add(keras.layers.SpatialDropout1D(rate=0.1,name=\"Dropout_layer2\"))\n",
        "    model.add(keras.layers.Conv1D(filters=80,activation=\"tanh\",name=\"Conv1d3\",kernel_size=4,strides=1,padding=\"same\",use_bias=True,bias_initializer=initializers.Zeros(),kernel_initializer=init))\n",
        "    model.add(keras.layers.MaxPool1D(pool_size=4,strides=1,name=\"MaxPooling3\",padding=\"same\"))\n",
        "    model.add(keras.layers.SpatialDropout1D(rate=0.1,name=\"Dropout_layer\"))\n",
        "    forward_layer = layers.LSTM(50, return_sequences=True,activation='tanh')\n",
        "    backward_layer = layers.LSTM(50, activation='tanh', return_sequences=True,\n",
        "                       go_backwards=True)\n",
        "    model.add(keras.layers.Bidirectional(forward_layer, backward_layer=backward_layer))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1,activation=\"sigmoid\",name=\"output\", kernel_initializer=init, bias_initializer=initializers.Zeros()))\n",
        "    model._name=\"CNNB_LSTM\"\n",
        "    # monitor=layers.EarlyStopping(monitor=\"val_loss\",mode=\"min\",patience=15,restore_best_weights=True)\n",
        "    model.compile(loss='binary_crossentropy',optimizer=tf.optimizers.Adam(learning_rate=lr),metrics=['accuracy'])\n",
        "    model.fit(input_train,output_train,epochs=30,batch_size=128,validation_data=(test21Input,test21Output),callbacks=[])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiouzZfGcwa6"
      },
      "outputs": [],
      "source": [
        "  \n",
        "# trainInput , trainOutput ,  scaler , encoder = preprocessingBinaryClass('drive/MyDrive/KDDTrain+.csv')\n",
        "# testInput , testOutput , *_ = preprocessingBinaryClass('drive/MyDrive/KDDTest+.csv' , scaler , encoder, False)\n",
        "# test21Input , test21Output , *_ = preprocessingBinaryClass('drive/MyDrive/KDDTest-21.csv' ,  scaler , encoder,False)\n",
        "\n",
        "\n",
        "trainInput , trainOutput , out , scaler , inEncoder , outEncoder = preprocessingFiveClasses('drive/MyDrive/KDDTrain+.csv' )\n",
        "testInput , testOutput , *_ = preprocessingFiveClasses('drive/MyDrive/KDDTest+.csv' , scaler , inEncoder , outEncoder , False  )\n",
        "test21Input , test21Output ,  *_ = preprocessingFiveClasses('drive/MyDrive/KDDTest-21.csv' , scaler , inEncoder , outEncoder , False )\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}